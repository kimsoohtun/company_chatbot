import streamlit as st
import pandas as pd
import pdfplumber
from docx import Document
import google.generativeai as genai

# --- 1. ì„¤ì • ë° UI ---
st.set_page_config(page_title="ì‚¬ë‚´ ê·œì • ì±—ë´‡", layout="wide")
st.title("ğŸ¤– 2026 í†µí•© ê·œì • ì•ˆë‚´ ì±—ë´‡")

with st.sidebar:
    api_key = st.text_input("Gemini API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")
    if api_key:
        genai.configure(api_key=api_key)
    
    st.divider()
    st.subheader("íŒŒì¼ ì—…ë¡œë“œ")
    uploaded_files = st.file_uploader("ë¬¸ì„œ ì„ íƒ (PDF, XLSX, DOCX)", 
                                    accept_multiple_files=True, 
                                    type=['pdf', 'xlsx', 'docx'])
    gsheet_url = st.text_input("êµ¬ê¸€ ì‹œíŠ¸ URL")

# --- 2. í…ìŠ¤íŠ¸ ì¶”ì¶œ ë¡œì§ ---
def extract_text(files, g_url):
    text_data = ""
    sources = []
    for f in files:
        content = ""
        if f.name.endswith('.pdf'):
            with pdfplumber.open(f) as pdf:
                content = "\n".join([p.extract_text() for p in pdf.pages if p.extract_text()])
        elif f.name.endswith('.docx'):
            content = "\n".join([p.text for p in Document(f).paragraphs])
        elif f.name.endswith('.xlsx'):
            content = pd.read_excel(f).to_string()
        text_data += f"\n\n[ì¶œì²˜: {f.name}]\n{content}"
        sources.append(f.name)
    
    if g_url:
        try:
            csv_url = g_url.replace('/edit#gid=', '/export?format=csv&gid=') if "edit" in g_url else g_url
            df = pd.read_csv(csv_url)
            text_data += f"\n\n[ì¶œì²˜: êµ¬ê¸€ ì‹œíŠ¸]\n{df.to_string()}"
            sources.append("êµ¬ê¸€ ì‹œíŠ¸")
        except: pass
    return text_data, sources

# --- 3. ì±„íŒ… ì—”ì§„ ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# ì§€ì‹ êµ¬ì¶•
knowledge_base, source_list = extract_text(uploaded_files, gsheet_url)

# ëŒ€í™” ì¶œë ¥
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ì§ˆë¬¸ ì²˜ë¦¬
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
    if not api_key:
        st.error("API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            try:
                # ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ” ëª¨ë¸ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒ (Gemini 2.5 Flash ê¶Œì¥)
                model = genai.GenerativeModel('gemini-2.5-flash')
                
                # ë³€ìˆ˜ëª…ì„ full_queryë¡œ í†µì¼í•˜ì—¬ ì—ëŸ¬ ë°©ì§€
                full_query = f"""ë„ˆëŠ” ì‚¬ë‚´ ê·œì • ì „ë¬¸ê°€ì•¼. ë‹¤ìŒ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì¤˜.
                ë‹µë³€ ëì— ì°¸ê³ í•œ ë¬¸ì„œëª…ì„ ì ì–´ì¤˜. ëª¨ë¥´ë©´ 'ì¸ì‚¬íŒ€ ë¬¸ì˜'ë¼ê³  í•´.
                
                [ì§€ì‹ ë² ì´ìŠ¤]
                {knowledge_base}
                
                ì§ˆë¬¸: {prompt}"""
                
                response = model.generate_content(full_query)
                st.markdown(response.text)
                st.session_state.messages.append({"role": "assistant", "content": response.text})
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")