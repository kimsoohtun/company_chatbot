import streamlit as st
import pandas as pd
import pdfplumber
from docx import Document
import google.generativeai as genai
import os

# --- 1. ê´€ë¦¬ì ì„¤ì • (Secrets ìš°ì„ ) ---
try:
    # ë°°í¬ í™˜ê²½ (Streamlit Secrets ì‚¬ìš©)
    api_key = st.secrets["GEMINI_API_KEY"]
    gsheet_url = st.secrets["GSHEET_URL"]
except:
    # ë¡œì»¬ í…ŒìŠ¤íŠ¸ í™˜ê²½ìš© (ë¹„ì›Œë‘ê³  secrets.toml ì‚¬ìš© ê¶Œì¥)
    api_key = "" 
    gsheet_url = "" 

if api_key:
    genai.configure(api_key=api_key)

# --- 2. í…ìŠ¤íŠ¸ ì¶”ì¶œ ë¡œì§ (íŒŒì¼ ê²½ë¡œ ëŒ€ì‘) ---
def extract_text_from_folder(folder_path, g_url):
    text_data = ""
    sources = []
    
    # ì§€ì •ëœ í´ë”(data) ë‚´ì˜ íŒŒì¼ë“¤ì„ ìë™ìœ¼ë¡œ ì½ê¸°
    if os.path.exists(folder_path):
        for filename in os.listdir(folder_path):
            file_path = os.path.join(folder_path, filename)
            content = ""
            try:
                if filename.endswith('.pdf'):
                    with pdfplumber.open(file_path) as pdf:
                        content = "\n".join([p.extract_text() for p in pdf.pages if p.extract_text()])
                elif filename.endswith('.docx'):
                    content = "\n".join([p.text for p in Document(file_path).paragraphs])
                elif filename.endswith('.xlsx'): 
                    content = pd.read_excel(file_path).to_string()
                
                if content:
                    text_data += f"\n\n[ì¶œì²˜: {filename}]\n{content}"
                    sources.append(filename)
            except Exception as e:
                st.error(f"íŒŒì¼ {filename} ì½ê¸° ì‹¤íŒ¨: {e}")

    # êµ¬ê¸€ ì‹œíŠ¸ ì²˜ë¦¬
    if g_url:
        try:
            csv_url = g_url.replace('/edit#gid=', '/export?format=csv&gid=') if "edit" in g_url else g_url
            df = pd.read_csv(csv_url)
            text_data += f"\n\n[ì¶œì²˜: êµ¬ê¸€ ì‹œíŠ¸]\n{df.to_string()}"
            sources.append("êµ¬ê¸€ ì‹œíŠ¸")
        except: pass
        
    return text_data, sources

# --- 3. UI êµ¬ì„± (ì§ì›ìš© ê¹”ë”í•œ í™”ë©´) ---
# ì‚¬ì´ë“œë°”ë¥¼ ê¸°ë³¸ì ìœ¼ë¡œ ë‹«ì•„ë‘ê³  ë©”ì¸ í™”ë©´ì— ì§‘ì¤‘í•˜ê²Œ í•©ë‹ˆë‹¤.
st.set_page_config(page_title="ì‚¬ë‚´ ê·œì • ì±—ë´‡", layout="centered", initial_sidebar_state="collapsed")
st.title("ğŸ¤– 2026 í†µí•© ê·œì • ì•ˆë‚´ ì±—ë´‡")
st.info("ì•ˆë…•í•˜ì„¸ìš”! ì‚¬ë‚´ ê·œì •ì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”.")
st.markdown("---")

# ì§€ì‹ êµ¬ì¶• (data í´ë”ë¥¼ ìë™ìœ¼ë¡œ ì½ìŒ)
# GitHub ì €ì¥ì†Œì— 'data' í´ë”ë¥¼ ë§Œë“¤ê³  ë¬¸ì„œë¥¼ ë„£ì–´ë‘ì–´ì•¼ í•©ë‹ˆë‹¤.
knowledge_base, source_list = extract_text_from_folder("data", gsheet_url)

if "messages" not in st.session_state:
    st.session_state.messages = []

# ëŒ€í™” ë‚´ìš© í‘œì‹œ
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# --- 4. ì§ˆë¬¸ ì²˜ë¦¬ ---
if prompt := st.chat_input("ê¶ê¸ˆí•œ ê·œì •ì„ ë¬¼ì–´ë³´ì„¸ìš”."):
    if not api_key:
        st.error("ê´€ë¦¬ì ì„¤ì •(API Key)ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        # ì‚¬ìš©ì ë©”ì‹œì§€ ê¸°ë¡ ë° ì¶œë ¥
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            try:
                # 404 ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ ëª¨ë¸ëª…ì„ 'gemini-1.5-flash'ë¡œ ì •í™•íˆ ì§€ì •í•©ë‹ˆë‹¤.
                model = genai.GenerativeModel('gemini-1.5-flash') 
                
                # 429 ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ ì§€ì‹ ë² ì´ìŠ¤ì˜ ì–‘ì„ ì œí•œí•©ë‹ˆë‹¤.
                safe_context = knowledge_base[:70000]
                
                full_query = f"""ë„ˆëŠ” ì‚¬ë‚´ ê·œì • ì „ë¬¸ê°€ì•¼. ì•„ë˜ ì œê³µëœ [ì§€ì‹ ë² ì´ìŠ¤]ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì¤˜.
                ë‹µë³€ ëì— 'ì°¸ê³  ë¬¸ì„œ: [ë¬¸ì„œëª…]'ì„ ê¼­ ì ì–´ì¤˜. 
                ëª¨ë¥´ëŠ” ë‚´ìš©ì€ ë°˜ë“œì‹œ 'ì¸ì‚¬íŒ€ì— ë¬¸ì˜í•˜ì„¸ìš”'ë¼ê³  ë‹µë³€í•´. 
                
                [ì§€ì‹ ë² ì´ìŠ¤(ì¼ë¶€)]
                {safe_context}
                
                ì§ˆë¬¸: {prompt}"""
                
                # ë‹µë³€ ìƒì„±
                response = model.generate_content(full_query)
                
                # ê²°ê³¼ ì¶œë ¥ ë° ì €ì¥
                st.markdown(response.text)
                st.session_state.messages.append({"role": "assistant", "content": response.text})
                
            except Exception as e:
                # ì—ëŸ¬ ë©”ì‹œì§€ì— ë”°ë¥¸ ë§ì¶¤í˜• ì•ˆë‚´
                if "429" in str(e):
                    st.error("âš ï¸ ìš”ì²­ì´ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤. ì•½ 1ë¶„ ë’¤ì— ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
                elif "404" in str(e):
                    st.error("âš ï¸ ëª¨ë¸ ì„¤ì • ì˜¤ë¥˜ì…ë‹ˆë‹¤. ëª¨ë¸ëª…ì„ 'gemini-1.5-flash'ë¡œ í™•ì¸í•´ ì£¼ì„¸ìš”.")
                else:
                    st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")





