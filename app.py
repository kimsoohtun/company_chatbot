import streamlit as st
import pandas as pd
import google.generativeai as genai

# --- 1. ì„¤ì • ë° API ì—°ê²° ---
try:
    # Streamlit Secretsì—ì„œ API í‚¤ì™€ êµ¬ê¸€ ì‹œíŠ¸ URLì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    api_key = st.secrets["GEMINI_API_KEY"]
    gsheet_url = st.secrets["GSHEET_URL"]
except Exception:
    api_key = ""
    gsheet_url = ""

if api_key:
    genai.configure(api_key=api_key)

# --- 2. êµ¬ê¸€ ì‹œíŠ¸ ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ (ì˜¤ë¥˜ ë°©ì§€) ---
def load_gsheet_data(url):
    if not url:
        return "ë°ì´í„°ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    try:
        # êµ¬ê¸€ ì‹œíŠ¸ URLì„ CSV ë‚´ë³´ë‚´ê¸° í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        csv_url = url.replace('/edit#gid=', '/export?format=csv&gid=') if "edit" in url else url
        if "export?format=csv" not in csv_url:
            csv_url = csv_url.rstrip('/') + '/export?format=csv'
            
        # í˜•ì‹ì´ ê¹¨ì§„ í–‰(Bad lines)ì„ ê±´ë„ˆë›°ì–´ ì‹œíŠ¸ ì½ê¸° ì˜¤ë¥˜ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
        df = pd.read_csv(csv_url, on_bad_lines='skip', engine='python')
        return df.to_string(index=False)
    except Exception as e:
        return f"ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

# --- 3. UI êµ¬ì„± ---
st.set_page_config(page_title="ì‚¬ë‚´ ê·œì • ì±—ë´‡", layout="centered")
st.title("ğŸ¤– ì‚¬ë‚´ ê·œì • ì•ˆë‚´ ì±—ë´‡ (ì‹œíŠ¸ ê¸°ë°˜)")
st.info("í˜„ì¬ êµ¬ê¸€ ì‹œíŠ¸ì— ë“±ë¡ëœ ìµœì‹  ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.")

# ì§€ì‹ ë² ì´ìŠ¤ êµ¬ì¶• (êµ¬ê¸€ ì‹œíŠ¸ë§Œ ì½ìŒ)
knowledge_base = load_gsheet_data(gsheet_url)

if "messages" not in st.session_state:
    st.session_state.messages = []

# ê¸°ì¡´ ëŒ€í™” í‘œì‹œ
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# --- 4. ì§ˆë¬¸ ì²˜ë¦¬ ---
if prompt := st.chat_input("ê¶ê¸ˆí•œ ì‚¬ë‚´ ê·œì •ì„ ë¬¼ì–´ë³´ì„¸ìš”."):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ê¸°ë¡
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        try:
            # [cite_start]404 ì˜¤ë¥˜ í•´ê²°: ëª¨ë¸ ê²½ë¡œë¥¼ ëª…ì‹œì ìœ¼ë¡œ í˜¸ì¶œí•©ë‹ˆë‹¤. [cite: 1]
            model = genai.GenerativeModel('gemini-1.5-flash')
            
            # [cite_start]429 ì˜¤ë¥˜ í•´ê²°: í† í° í•œë„ë¥¼ ë„˜ì§€ ì•Šê²Œ ì§€ì‹ ë² ì´ìŠ¤ë¥¼ ìë¦…ë‹ˆë‹¤. [cite: 3]
            # [cite_start]í•œê¸€ ê¸°ì¤€ ì•½ 50,000ì ë‚´ì™¸ê°€ ë¬´ë£Œ í‹°ì–´ì—ì„œ ê°€ì¥ ì•ˆì •ì ì…ë‹ˆë‹¤. [cite: 2]
            safe_context = knowledge_base[:50000] 
            
            full_query = f"""ë„ˆëŠ” ì‚¬ë‚´ ê·œì • ì „ë¬¸ê°€ì•¼. ì•„ë˜ [ì§€ì‹ ë² ì´ìŠ¤]ì˜ ë‚´ìš©ë§Œ ì°¸ê³ í•´ì„œ ë‹µë³€í•´ì¤˜.
ë§Œì•½ ì§€ì‹ ë² ì´ìŠ¤ì— ì—†ëŠ” ë‚´ìš©ì´ë¼ë©´ 'í•´ë‹¹ ë‚´ìš©ì€ ì¸ì‚¬íŒ€ì— ë¬¸ì˜í•˜ì„¸ìš”'ë¼ê³  ë‹µë³€í•´.

[ì§€ì‹ ë² ì´ìŠ¤]
{safe_context}

ì§ˆë¬¸: {prompt}"""
            
            # [cite_start]AI ë‹µë³€ ìƒì„± [cite: 4]
            response = model.generate_content(full_query)
            
            if response.text:
                st.markdown(response.text)
                st.session_state.messages.append({"role": "assistant", "content": response.text})
            
        except Exception as e:
            # [cite_start]429(í• ë‹¹ëŸ‰ ì´ˆê³¼) ë°œìƒ ì‹œ ë³„ë„ ì•ˆë‚´ [cite: 5]
            if "429" in str(e):
                [cite_start]st.error("âš ï¸ í•œêº¼ë²ˆì— ë„ˆë¬´ ë§ì€ ì§ˆë¬¸ì´ ë“¤ì–´ì™”ìŠµë‹ˆë‹¤. ì•½ 1ë¶„ ë’¤ì— ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”. [cite: 5]")
            else:
                st.error(f"âš ï¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
